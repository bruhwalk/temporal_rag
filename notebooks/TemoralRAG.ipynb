{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d488cb-8c54-4177-8d80-d3bb6ef323e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openpyxl pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f399f7-a595-4b07-b733-bb6367941289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlcore/conda/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "channels = pd.read_excel(\"../data/tg_channels.xlsx\")\n",
    "#df = pd.read_csv(\"../data/cleaned_news_exp.csv\")[[\"message_id\", \"id_channel\", \"message\", \"date\", \"topic\"]]\n",
    "df = pd.read_parquet(\"../data/tg_news_full.parquet\")[[\"message_id\", \"id_channel\", \"message\", \"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b7ed69-3a6e-48e8-bf9d-8c9c7de736fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_channel_w(\n",
    "    df: pd.DataFrame,\n",
    "    channels_df: pd.DataFrame,\n",
    "    news_id_col: str = \"id_channel\",\n",
    "    chan_id_col: str = \"id\",\n",
    "    subs_col: str = \"subscribers\",\n",
    "    weight_col: str = \"channel_w\",) -> pd.DataFrame:\n",
    "    ch = channels_df[[chan_id_col, subs_col]].copy()\n",
    "    ch[chan_id_col] = pd.to_numeric(ch[chan_id_col], errors=\"coerce\").astype(\"Int64\")\n",
    "    ch[subs_col] = pd.to_numeric(ch[subs_col], errors=\"coerce\").fillna(0).astype(float)\n",
    "    id2subs = dict(zip(ch[chan_id_col], ch[subs_col]))\n",
    "\n",
    "    out = df.copy()\n",
    "    out[news_id_col] = pd.to_numeric(out[news_id_col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    subs = out[news_id_col].map(id2subs).fillna(0.0).to_numpy(dtype=np.float32)\n",
    "    log_subs = np.log1p(subs)\n",
    "\n",
    "    mn, mx = float(log_subs.min()), float(log_subs.max())\n",
    "    if mx > mn:\n",
    "        w = (log_subs - mn) / (mx - mn)\n",
    "    else:\n",
    "        w = np.zeros_like(log_subs, dtype=np.float32)\n",
    "\n",
    "    out[weight_col] = w.astype(np.float32)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf2a27c-2557-4aef-acc6-bfdf9bea8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_map = (channels[[\"id\", \"name\"]]\n",
    "          .dropna()\n",
    "          .assign(id=lambda x: pd.to_numeric(x[\"id\"], errors=\"coerce\"))\n",
    "          .dropna(subset=[\"id\"])\n",
    "          .assign(id=lambda x: x[\"id\"].astype(int))\n",
    "          .set_index(\"id\")[\"name\"]\n",
    "          .to_dict())\n",
    "\n",
    "df = df.copy()\n",
    "df[\"id_channel\"] = pd.to_numeric(df[\"id_channel\"], errors=\"coerce\")\n",
    "df[\"channel_name\"] = df[\"id_channel\"].map(ch_map).fillna(df[\"id_channel\"].astype(\"Int64\").astype(str))\n",
    "df = attach_channel_w(df, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d52ac2-bde7-4917-87f2-c3f26a844a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def clean_news_text(t: str) -> str:\n",
    "    t = t or \"\"\n",
    "    t = re.sub(r\"#\\w+\", \" \", t)\n",
    "    t = re.sub(r\"[‚ö°Ô∏èüìàüìâüá∑üá∫‚úÖ‚ùóÔ∏èüî•‚¨õ ‚¨ú ‚ö´ ‚ö™üîπ]+\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def ensure_datetime(df: pd.DataFrame, col: str = \"date\") -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[col] = pd.to_datetime(d[col], utc=True, errors=\"coerce\")\n",
    "    d = d.dropna(subset=[col])\n",
    "    d[\"date_day\"] = d[col].dt.floor(\"D\")\n",
    "    return d\n",
    "\n",
    "df = ensure_datetime(df, \"date\")\n",
    "df[\"message_id\"] = df[\"message_id\"].astype(str)\n",
    "df[\"message\"] = df[\"message\"].fillna(\"\").astype(str).map(clean_news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b05d5ab-1cbd-4a6d-8f62-825f02d0456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>id_channel</th>\n",
       "      <th>message</th>\n",
       "      <th>date</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_w</th>\n",
       "      <th>date_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275548</td>\n",
       "      <td>3</td>\n",
       "      <td>–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –°–ª–æ–≤–∞–∫–∏–∏ –æ–±—Å—É–¥–∏—Ç –º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º...</td>\n",
       "      <td>2025-01-02 17:00:02+00:00</td>\n",
       "      <td>–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275547</td>\n",
       "      <td>3</td>\n",
       "      <td>–í –î–¢–ü —Å —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–º –∞–≤—Ç–æ–±—É—Å–æ–º –≤ –¢–∞–∏–ª–∞–Ω–¥–µ –ø–æ—Å...</td>\n",
       "      <td>2025-01-02 16:40:53+00:00</td>\n",
       "      <td>–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275546</td>\n",
       "      <td>3</td>\n",
       "      <td>–ü—Ä–µ–º—å–µ—Ä –ò–∑—Ä–∞–∏–ª—è –ù–µ—Ç–∞–Ω—å—è—Ö—É –≤—ã–ø–∏—Å–∞–Ω –∏–∑ –±–æ–ª—å–Ω–∏—Ü—ã ...</td>\n",
       "      <td>2025-01-02 16:20:12+00:00</td>\n",
       "      <td>–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275545</td>\n",
       "      <td>3</td>\n",
       "      <td>–ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –≤ –ø–æ–¥—Ä—ã–≤–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è Tesla Cyber...</td>\n",
       "      <td>2025-01-02 15:54:29+00:00</td>\n",
       "      <td>–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275543</td>\n",
       "      <td>3</td>\n",
       "      <td>–°–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è. –û–±—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –≥–ª–∞–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –Ω–∞ ...</td>\n",
       "      <td>2025-01-02 15:32:55+00:00</td>\n",
       "      <td>–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-01-02 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  message_id  id_channel                                            message  \\\n",
       "0     275548           3  –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –°–ª–æ–≤–∞–∫–∏–∏ –æ–±—Å—É–¥–∏—Ç –º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º...   \n",
       "1     275547           3  –í –î–¢–ü —Å —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–º –∞–≤—Ç–æ–±—É—Å–æ–º –≤ –¢–∞–∏–ª–∞–Ω–¥–µ –ø–æ—Å...   \n",
       "2     275546           3  –ü—Ä–µ–º—å–µ—Ä –ò–∑—Ä–∞–∏–ª—è –ù–µ—Ç–∞–Ω—å—è—Ö—É –≤—ã–ø–∏—Å–∞–Ω –∏–∑ –±–æ–ª—å–Ω–∏—Ü—ã ...   \n",
       "3     275545           3  –ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π –≤ –ø–æ–¥—Ä—ã–≤–µ –∞–≤—Ç–æ–º–æ–±–∏–ª—è Tesla Cyber...   \n",
       "4     275543           3  –°–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è. –û–±—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –≥–ª–∞–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –Ω–∞ ...   \n",
       "\n",
       "                       date channel_name  channel_w                  date_day  \n",
       "0 2025-01-02 17:00:02+00:00  –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏        1.0 2025-01-02 00:00:00+00:00  \n",
       "1 2025-01-02 16:40:53+00:00  –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏        1.0 2025-01-02 00:00:00+00:00  \n",
       "2 2025-01-02 16:20:12+00:00  –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏        1.0 2025-01-02 00:00:00+00:00  \n",
       "3 2025-01-02 15:54:29+00:00  –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏        1.0 2025-01-02 00:00:00+00:00  \n",
       "4 2025-01-02 15:32:55+00:00  –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏        1.0 2025-01-02 00:00:00+00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82283b6-cbae-483e-8495-f4170eed9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77a872d-7698-435d-a369-479b7b1e534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def tokenize_ru(text: str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^0-9a-z–∞-—è—ë\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()\n",
    "\n",
    "corpus_tok = [tokenize_ru(t) for t in df[\"message\"].tolist()]\n",
    "bm25 = BM25Okapi(corpus_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ea3567-02fb-40d0-a13e-e77de60fe2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install faiss-cpu faiss-gpu-cu12 faiss-gpu-cu11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4290f08a-82d8-40b6-af73-e89d0386bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-large\" \n",
    "encoder = SentenceTransformer(MODEL_NAME, device=\"cuda\")  \n",
    "texts = df[\"message\"].tolist()\n",
    "doc_inputs = [\"passage: \" + t for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7436ed1c-6f09-413b-ae3b-03d76af07d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_docs = encoder.encode(\n",
    "#     doc_inputs,\n",
    "#     batch_size=64,\n",
    "#     show_progress_bar=True,\n",
    "#     normalize_embeddings=True,\n",
    "# ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb37ea91-457f-407e-bff0-7e743bf4430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "\n",
    "# dim = E_docs.shape[1]\n",
    "# index = faiss.IndexFlatIP(dim)      \n",
    "# index.add(E_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab301b0c-3979-48dd-97f9-c3c16f713b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import faiss\n",
    "# import pickle\n",
    "\n",
    "# OUT = Path(\"indexes\")\n",
    "# OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# #rowmap\n",
    "# rowmap = df[[\"message_id\",\"date\",\"date_day\",\"id_channel\",\"channel_name\"]].copy()\n",
    "# rowmap.to_parquet(OUT / \"rowmap.parquet\", index=False)\n",
    "\n",
    "# np.save(OUT / \"E_docs_e5_large.npy\", E_docs)\n",
    "\n",
    "# faiss.write_index(index, str(OUT / \"faiss_e5_large.index\"))\n",
    "\n",
    "# with open(OUT / \"bm25_corpus_tok.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(corpus_tok, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c4f45-33ca-49b9-b735-599e5d851055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2760a8-4f82-4159-899f-e94447a94e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "INP = Path(\"indexes\")\n",
    "\n",
    "rowmap = pd.read_parquet(INP / \"rowmap.parquet\")\n",
    "\n",
    "E_docs = np.load(INP / \"E_docs_e5_large.npy\")\n",
    "index = faiss.read_index(str(INP / \"faiss_e5_large.index\"))\n",
    "\n",
    "with open(INP / \"bm25_corpus_tok.pkl\", \"rb\") as f:\n",
    "    corpus_tok = pickle.load(f)\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "bm25 = BM25Okapi(corpus_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcef3d8f-f6d5-4ded-b27d-b86e1b53b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(rowmap) == E_docs.shape[0]\n",
    "assert len(rowmap) == index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17969e2a-8bfc-414a-86a7-da15a18cfedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde85e14-f892-47a2-b585-4af1c1b8b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "except Exception:\n",
    "    faiss = None\n",
    "\n",
    "_URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "_HANDLE_RE = re.compile(r\"@\\w+\")\n",
    "_WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "def _normalize_for_dedup(text: str, mask_numbers: bool = True) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text.lower()\n",
    "    t = _URL_RE.sub(\" \", t)\n",
    "    t = _HANDLE_RE.sub(\" \", t)\n",
    "    t = re.sub(r\"[^\\w\\s%.,\\-]+\", \" \", t, flags=re.UNICODE)\n",
    "    if mask_numbers:\n",
    "        t = re.sub(r\"\\d+(?:[.,]\\d+)?\", \"<num>\", t)\n",
    "    t = _WS_RE.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def _stable_hash(s: str) -> str:\n",
    "    return hashlib.md5(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def _union_find(n: int):\n",
    "    parent = np.arange(n, dtype=np.int32)\n",
    "    rank = np.zeros(n, dtype=np.int8)\n",
    "    def find(x: int) -> int:\n",
    "        while parent[x] != x:\n",
    "            parent[x] = parent[parent[x]]\n",
    "            x = parent[x]\n",
    "        return int(x)\n",
    "    def union(a: int, b: int) -> None:\n",
    "        ra, rb = find(a), find(b)\n",
    "        if ra == rb:\n",
    "            return\n",
    "        if rank[ra] < rank[rb]:\n",
    "            parent[ra] = rb\n",
    "        elif rank[ra] > rank[rb]:\n",
    "            parent[rb] = ra\n",
    "        else:\n",
    "            parent[rb] = ra\n",
    "            rank[ra] += 1\n",
    "    return find, union\n",
    "\n",
    "def dedup_cluster_candidates_time(\n",
    "    cand: pd.DataFrame,\n",
    "    encoder,\n",
    "    text_col: str = \"message\",\n",
    "    date_col: str = \"date_day\",\n",
    "    channel_col: str = \"channel_name\",\n",
    "    score_col: str = \"score_rrf\",\n",
    "    sim_threshold: float = 0.95,\n",
    "    knn: int = 20,\n",
    "    keep_per_cluster: int = 1,\n",
    "    mask_numbers: bool = True,\n",
    "    max_day_diff: int = 1,\n",
    "    overwrite_channel: bool = True,\n",
    "    channel_join: str = \"; \",\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    if cand is None or len(cand) == 0:\n",
    "        return cand, pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    cand = cand.copy().reset_index(drop=True)\n",
    "\n",
    "    dts = pd.to_datetime(cand[date_col], errors=\"coerce\", utc=True).dt.normalize()\n",
    "    cand[\"_dt\"] = dts\n",
    "    cand[\"_dt_str\"] = cand[\"_dt\"].dt.strftime(\"%Y-%m-%d\").fillna(\"\")\n",
    "\n",
    "    norm = cand[text_col].fillna(\"\").map(lambda s: _normalize_for_dedup(s, mask_numbers=mask_numbers))\n",
    "    cand[\"_h\"] = norm.map(_stable_hash)\n",
    "\n",
    "    cand[\"_hk\"] = cand[\"_h\"].astype(str) + \"|\" + cand[\"_dt_str\"].astype(str)\n",
    "\n",
    "    if score_col in cand.columns:\n",
    "        rep_idx = (\n",
    "            cand.sort_values(score_col, ascending=False)\n",
    "                .groupby(\"_hk\", as_index=False)\n",
    "                .head(1)\n",
    "                .index.to_numpy()\n",
    "        )\n",
    "    else:\n",
    "        rep_idx = cand.groupby(\"_hk\", as_index=False).head(1).index.to_numpy()\n",
    "\n",
    "    rep = cand.loc[rep_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    texts = rep[text_col].fillna(\"\").tolist()\n",
    "    X = encoder.encode(texts, normalize_embeddings=True, show_progress_bar=False).astype(np.float32)\n",
    "\n",
    "    rep_dt = pd.to_datetime(rep[\"_dt\"], errors=\"coerce\", utc=True)\n",
    "    rep_dt = rep_dt.dt.tz_convert(None).dt.normalize().to_numpy(dtype=\"datetime64[D]\")\n",
    "\n",
    "    m = len(rep)\n",
    "    find, union = _union_find(m)\n",
    "\n",
    "    if m > 1:\n",
    "        if faiss is None:\n",
    "            S = X @ X.T\n",
    "            for i in range(m):\n",
    "                js = np.where(S[i, i+1:] >= sim_threshold)[0] + (i + 1)\n",
    "                for j in js:\n",
    "                    if np.isnat(rep_dt[i]) or np.isnat(rep_dt[j]):\n",
    "                        continue\n",
    "                    day_diff = abs(int((rep_dt[i] - rep_dt[j]).astype(\"timedelta64[D]\").astype(int)))\n",
    "                    if day_diff <= max_day_diff:\n",
    "                        union(i, int(j))\n",
    "        else:\n",
    "            idx = faiss.IndexFlatIP(X.shape[1])\n",
    "            idx.add(X)\n",
    "            D, I = idx.search(X, min(knn, m))\n",
    "            for i in range(m):\n",
    "                for score, j in zip(D[i], I[i]):\n",
    "                    if j < 0 or j == i:\n",
    "                        continue\n",
    "                    if float(score) < sim_threshold:\n",
    "                        continue\n",
    "                    if np.isnat(rep_dt[i]) or np.isnat(rep_dt[j]):\n",
    "                        continue\n",
    "                    day_diff = abs(int((rep_dt[i] - rep_dt[j]).astype(\"timedelta64[D]\").astype(int)))\n",
    "                    if day_diff <= max_day_diff:\n",
    "                        union(i, int(j))\n",
    "\n",
    "    rep_cluster = np.array([find(i) for i in range(m)], dtype=np.int32)\n",
    "    _, rep_cluster = np.unique(rep_cluster, return_inverse=True)\n",
    "    rep[\"_rep_cluster\"] = rep_cluster\n",
    "\n",
    "    hk_to_cluster = dict(zip(rep[\"_hk\"].tolist(), rep[\"_rep_cluster\"].tolist()))\n",
    "    cand[\"_cluster_id\"] = cand[\"_hk\"].map(hk_to_cluster)\n",
    "\n",
    "    cand[\"_cluster_id\"] = cand[\"_cluster_id\"].fillna(-1).astype(np.int32)\n",
    "\n",
    "    cluster_sizes = cand.groupby(\"_cluster_id\").size()\n",
    "\n",
    "    if channel_col in cand.columns:\n",
    "        ch_joined = (\n",
    "            cand.groupby(\"_cluster_id\")[channel_col]\n",
    "                .apply(lambda s: channel_join.join(sorted({str(x) for x in s.dropna().tolist()})))\n",
    "        )\n",
    "    else:\n",
    "        ch_joined = pd.Series(dtype=str)\n",
    "\n",
    "    if score_col in cand.columns:\n",
    "        cand_dedup = (\n",
    "            cand.sort_values(score_col, ascending=False)\n",
    "                .groupby(\"_cluster_id\", group_keys=False)\n",
    "                .head(keep_per_cluster)\n",
    "                .reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        cand_dedup = (\n",
    "            cand.groupby(\"_cluster_id\", group_keys=False)\n",
    "                .head(keep_per_cluster)\n",
    "                .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "    cand_dedup[\"cluster_size\"] = cand_dedup[\"_cluster_id\"].map(cluster_sizes).astype(int)\n",
    "\n",
    "    if channel_col in cand.columns:\n",
    "        cand_dedup[\"channel_all\"] = cand_dedup[\"_cluster_id\"].map(ch_joined).fillna(\"\")\n",
    "        cand_dedup[\"channel_primary\"] = cand_dedup[channel_col].astype(str)\n",
    "        if overwrite_channel and channel_col in cand_dedup.columns:\n",
    "            cand_dedup[channel_col] = cand_dedup[\"channel_all\"]\n",
    "\n",
    "    cand_dedup = cand_dedup.drop(columns=[\"_h\", \"_hk\", \"_dt\", \"_dt_str\"], errors=\"ignore\")\n",
    "\n",
    "    clusters = cand[[\"_cluster_id\"]].copy()\n",
    "    clusters[\"cluster_size\"] = clusters[\"_cluster_id\"].map(cluster_sizes).astype(int)\n",
    "\n",
    "    members = cand[[\"_cluster_id\"]].copy()\n",
    "    for c in [\"date_day\", \"date\", \"channel_name\", \"channel\", \"message_id\", \"score_rrf\"]:\n",
    "        if c in cand.columns:\n",
    "            members[c] = cand[c]\n",
    "    members[\"text_snip\"] = cand[text_col].fillna(\"\").map(lambda s: s[:250])\n",
    "\n",
    "    return cand_dedup, clusters, members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f76acc5-fc79-4909-bfdd-c4211312fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def snippet(t: str, n: int = 1000) -> str:\n",
    "    return t[:n]\n",
    "\n",
    "def _topk_indices_from_scores(scores: np.ndarray, k: int) -> np.ndarray:\n",
    "    k = min(k, len(scores))\n",
    "    if k <= 0:\n",
    "        return np.array([], dtype=int)\n",
    "    if k == len(scores):\n",
    "        idx = np.argsort(-scores)\n",
    "    else:\n",
    "        idx = np.argpartition(-scores, k - 1)[:k]\n",
    "        idx = idx[np.argsort(-scores[idx])]\n",
    "    return idx.astype(int)\n",
    "\n",
    "def dense_candidates_faiss(index, encoder, query: str, topN: int = 500):\n",
    "    qv = encoder.encode(\n",
    "        [\"query: \" + query],\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    ).astype(np.float32)\n",
    "    scores, idx = index.search(qv, topN)\n",
    "    return idx[0].astype(int), scores[0].astype(np.float32)\n",
    "\n",
    "def _compute_time_arrays(df: pd.DataFrame, rowpos: np.ndarray, anchor_date, date_col: str):\n",
    "    ad = pd.to_datetime(anchor_date, utc=True).normalize()\n",
    "    dts = pd.to_datetime(df.loc[rowpos, date_col], errors=\"coerce\", utc=True).dt.normalize()\n",
    "    age = (ad - dts).dt.days.to_numpy(dtype=np.float32)\n",
    "    age = np.where(np.isfinite(age), age, 1e9).astype(np.float32)\n",
    "    age = np.where(age < 0, 1e9, age).astype(np.float32)\n",
    "    return dts, age\n",
    "\n",
    "def _time_rank_from_age(age_days: np.ndarray) -> np.ndarray:\n",
    "    order = np.argsort(age_days, kind=\"stable\")\n",
    "    rank = np.empty_like(order, dtype=np.int32)\n",
    "    rank[order] = np.arange(1, len(order) + 1, dtype=np.int32)\n",
    "    return rank\n",
    "\n",
    "def hybrid_retrieve_rrf(\n",
    "    df: pd.DataFrame,\n",
    "    index,\n",
    "    encoder,\n",
    "    bm25,\n",
    "    tokenize_fn,\n",
    "    query: str,\n",
    "    k: int = 50,\n",
    "    topN_each: int = 500,\n",
    "    k_rrf: int = 60,\n",
    "    w_dense: float = 1.0,\n",
    "    w_bm25: float = 1.0,\n",
    "    anchor_date: str | pd.Timestamp | None = None,\n",
    "    date_col: str = \"date_day\",\n",
    "    max_window_days: int | None = 365,\n",
    "    w_time: float = 0.5,\n",
    "    w_channel: float | None = None,\n",
    "    channel_w_col: str = \"channel_w\",\n",
    ") -> pd.DataFrame:\n",
    "    if anchor_date is not None:\n",
    "        ad = pd.to_datetime(anchor_date, utc=True).normalize()\n",
    "        if date_col not in df.columns:\n",
    "            raise KeyError(f\"date_col='{date_col}' not found in df.columns\")\n",
    "        dts_all = pd.to_datetime(df[date_col], errors=\"coerce\", utc=True).dt.normalize()\n",
    "        allowed = (dts_all <= ad)\n",
    "        if max_window_days is not None:\n",
    "            age_all = (ad - dts_all).dt.days\n",
    "            allowed &= (age_all >= 0) & (age_all <= int(max_window_days))\n",
    "        allowed_np = allowed.to_numpy(dtype=bool)\n",
    "    else:\n",
    "        allowed_np = None\n",
    "\n",
    "    d_idx, _ = dense_candidates_faiss(index, encoder, query, topN=topN_each)\n",
    "    if allowed_np is not None and len(d_idx) > 0:\n",
    "        d_idx = d_idx[allowed_np[d_idx]]\n",
    "    dense_rank = {int(rowpos): r for r, rowpos in enumerate(d_idx, start=1)}\n",
    "\n",
    "    if bm25 is None:\n",
    "        union = d_idx.astype(int)\n",
    "        if len(union) == 0:\n",
    "            return df.iloc[[]].copy().reset_index(drop=True)\n",
    "\n",
    "        rrf = w_dense / (k_rrf + np.arange(1, len(union) + 1, dtype=np.float32))\n",
    "\n",
    "        rank_time = None\n",
    "        if anchor_date is not None and w_time and len(union) > 0:\n",
    "            _, age = _compute_time_arrays(df, union, anchor_date, date_col)\n",
    "            rank_time = _time_rank_from_age(age)\n",
    "            rrf = rrf + (w_time / (k_rrf + rank_time.astype(np.float32)))\n",
    "\n",
    "        order = np.argsort(-rrf)\n",
    "        union = union[order]\n",
    "        rrf = rrf[order]\n",
    "        if rank_time is not None:\n",
    "            rank_time = rank_time[order]\n",
    "\n",
    "        out = df.iloc[union].copy()\n",
    "        out[\"_rowpos\"] = union\n",
    "        out[\"score_rrf\"] = rrf\n",
    "        out[\"rank_dense\"] = out[\"_rowpos\"].map(lambda rp: dense_rank.get(int(rp), np.nan))\n",
    "        out[\"rank_bm25\"] = np.nan\n",
    "\n",
    "        if anchor_date is not None:\n",
    "            doc_day, age = _compute_time_arrays(df, union, anchor_date, date_col)\n",
    "            out[\"doc_day\"] = doc_day.dt.tz_localize(None)\n",
    "            out[\"age_days\"] = age\n",
    "            if rank_time is not None:\n",
    "                out[\"rank_time\"] = rank_time\n",
    "\n",
    "        if channel_w_col in out.columns:\n",
    "            if w_channel is None:\n",
    "                w_channel = 0.10 * float(np.std(out[\"score_rrf\"].to_numpy(dtype=np.float32)) or 1.0)\n",
    "            out[\"score_rrf\"] = out[\"score_rrf\"] + float(w_channel) * out[channel_w_col].astype(np.float32)\n",
    "            out = out.sort_values(\"score_rrf\", ascending=False)\n",
    "\n",
    "        return out.head(k).reset_index(drop=True)\n",
    "\n",
    "    bm_scores = bm25.get_scores(tokenize_fn(query)).astype(np.float32)\n",
    "    if allowed_np is not None:\n",
    "        bm_scores[~allowed_np] = -np.inf\n",
    "    b_idx = _topk_indices_from_scores(bm_scores, topN_each)\n",
    "    bm_rank = {int(rowpos): r for r, rowpos in enumerate(b_idx, start=1)}\n",
    "\n",
    "    union = np.array(sorted(set(dense_rank) | set(bm_rank)), dtype=int)\n",
    "    if len(union) == 0:\n",
    "        return df.iloc[[]].copy().reset_index(drop=True)\n",
    "\n",
    "    rrf = np.zeros(len(union), dtype=np.float32)\n",
    "    for j, rowpos in enumerate(union):\n",
    "        if rowpos in dense_rank:\n",
    "            rrf[j] += w_dense / (k_rrf + dense_rank[rowpos])\n",
    "        if rowpos in bm_rank:\n",
    "            rrf[j] += w_bm25 / (k_rrf + bm_rank[rowpos])\n",
    "\n",
    "    rank_time = None\n",
    "    if anchor_date is not None and w_time and len(union) > 0:\n",
    "        _, age = _compute_time_arrays(df, union, anchor_date, date_col)\n",
    "        rank_time = _time_rank_from_age(age)\n",
    "        rrf = rrf + (w_time / (k_rrf + rank_time.astype(np.float32)))\n",
    "\n",
    "    order = np.argsort(-rrf)\n",
    "    union = union[order]\n",
    "    rrf = rrf[order]\n",
    "    if rank_time is not None:\n",
    "        rank_time = rank_time[order]\n",
    "\n",
    "    out = df.iloc[union].copy()\n",
    "    out[\"_rowpos\"] = union\n",
    "    out[\"score_rrf\"] = rrf\n",
    "    out[\"rank_dense\"] = out[\"_rowpos\"].map(lambda rp: dense_rank.get(int(rp), np.nan))\n",
    "    out[\"rank_bm25\"] = out[\"_rowpos\"].map(lambda rp: bm_rank.get(int(rp), np.nan))\n",
    "\n",
    "    if anchor_date is not None:\n",
    "        doc_day, age = _compute_time_arrays(df, union, anchor_date, date_col)\n",
    "        out[\"doc_day\"] = doc_day.dt.tz_localize(None)\n",
    "\n",
    "        out[\"age_days\"] = age\n",
    "        if rank_time is not None:\n",
    "            out[\"rank_time\"] = rank_time\n",
    "\n",
    "    if channel_w_col in out.columns:\n",
    "        if w_channel is None:\n",
    "            w_channel = 0.10 * float(np.std(out[\"score_rrf\"].to_numpy(dtype=np.float32)) or 1.0)\n",
    "        out[\"score_rrf\"] = out[\"score_rrf\"] + float(w_channel) * out[channel_w_col].astype(np.float32)\n",
    "        out = out.sort_values(\"score_rrf\", ascending=False)\n",
    "\n",
    "    return out.head(k).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "149ac8fd-e146-4487-8cbb-3731554be0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-09-23 00:00:00+0000', tz='UTC'),\n",
       " Timestamp('2025-09-08 00:00:00+0000', tz='UTC'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date_day\"].min(), df[\"date_day\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc92482-2a6e-4757-a3a7-6b9a96e0c03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b39a2-ec1c-4e6b-8b3d-8878c8c8a67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0464504d-eaa9-480f-bb2f-a62c2e868ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers torch sentence-transformers accelerate vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91710dd3-0196-4c7b-812c-b319832c1b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA A100-SXM4-80GB\n",
      "VRAM(GB): 79.3\n",
      "Model max_position_embeddings: 32768\n",
      "INFO 01-10 05:16:14 [utils.py:253] non-default args: {'dtype': 'bfloat16', 'max_model_len': 19200, 'gpu_memory_utilization': 0.88, 'disable_log_stats': True, 'model': 'Qwen/Qwen2.5-32B-Instruct'}\n",
      "INFO 01-10 05:16:15 [model.py:514] Resolved architecture: Qwen2ForCausalLM\n",
      "INFO 01-10 05:16:15 [model.py:1661] Using max model len 19200\n",
      "INFO 01-10 05:16:15 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 01-10 05:16:17 [system_utils.py:136] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:24 [core.py:93] Initializing a V1 LLM engine (v0.13.0) with config: model='Qwen/Qwen2.5-32B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-32B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=19200, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=Qwen/Qwen2.5-32B-Instruct, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [8192], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m WARNING 01-10 05:16:24 [network_utils.py:36] The environment variable HOST_IP is deprecated and ignored, as it is often used by Docker and other software to interact with the container's network stack. Please use VLLM_HOST_IP instead to set the IP address for vLLM processes to communicate with each other.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:25 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.200.4.36:54853 backend=nccl\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:25 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:26 [gpu_model_runner.py:3562] Starting to load model Qwen/Qwen2.5-32B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m /home/mlcore/conda/lib/python3.10/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:29 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/17 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:   6% Completed | 1/17 [00:00<00:09,  1.67it/s]\n",
      "Loading safetensors checkpoint shards:  12% Completed | 2/17 [00:01<00:10,  1.48it/s]\n",
      "Loading safetensors checkpoint shards:  18% Completed | 3/17 [00:02<00:09,  1.44it/s]\n",
      "Loading safetensors checkpoint shards:  24% Completed | 4/17 [00:02<00:09,  1.40it/s]\n",
      "Loading safetensors checkpoint shards:  29% Completed | 5/17 [00:03<00:08,  1.37it/s]\n",
      "Loading safetensors checkpoint shards:  35% Completed | 6/17 [00:04<00:08,  1.37it/s]\n",
      "Loading safetensors checkpoint shards:  41% Completed | 7/17 [00:05<00:07,  1.35it/s]\n",
      "Loading safetensors checkpoint shards:  47% Completed | 8/17 [00:05<00:06,  1.33it/s]\n",
      "Loading safetensors checkpoint shards:  53% Completed | 9/17 [00:06<00:06,  1.33it/s]\n",
      "Loading safetensors checkpoint shards:  59% Completed | 10/17 [00:07<00:05,  1.31it/s]\n",
      "Loading safetensors checkpoint shards:  65% Completed | 11/17 [00:08<00:04,  1.30it/s]\n",
      "Loading safetensors checkpoint shards:  71% Completed | 12/17 [00:08<00:03,  1.29it/s]\n",
      "Loading safetensors checkpoint shards:  76% Completed | 13/17 [00:09<00:03,  1.26it/s]\n",
      "Loading safetensors checkpoint shards:  82% Completed | 14/17 [00:10<00:02,  1.26it/s]\n",
      "Loading safetensors checkpoint shards:  88% Completed | 15/17 [00:11<00:01,  1.35it/s]\n",
      "Loading safetensors checkpoint shards:  94% Completed | 16/17 [00:11<00:00,  1.38it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 17/17 [00:12<00:00,  1.36it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 17/17 [00:12<00:00,  1.35it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:43 [default_loader.py:308] Loading weights took 12.74 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:44 [gpu_model_runner.py:3659] Model loading took 61.0375 GiB memory and 17.320794 seconds\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:56 [backends.py:643] Using cache directory: /home/mlcore/.cache/vllm/torch_compile_cache/acdcfb9698/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:16:56 [backends.py:703] Dynamo bytecode transform time: 12.13 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:17 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 8192) from the cache, took 14.028 s\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:17 [monitor.py:34] torch.compile takes 26.16 s in total\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:18 [gpu_worker.py:375] Available KV cache memory: 7.22 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:18 [kv_cache_utils.py:1291] GPU KV cache size: 29,568 tokens\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:18 [kv_cache_utils.py:1296] Maximum concurrency for 19,200 tokens per request: 1.54x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51/51 [00:06<00:00,  7.81it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:03<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:29 [gpu_model_runner.py:4587] Graph capturing finished in 11 secs, took 4.11 GiB\n",
      "\u001b[0;36m(EngineCore_DP0 pid=11355)\u001b[0;0m INFO 01-10 05:17:29 [core.py:259] init engine (profile, create kv cache, warmup model) took 44.93 seconds\n",
      "INFO 01-10 05:17:31 [llm.py:360] Supported tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from vllm import LLM\n",
    "import torch\n",
    "\n",
    "MODEL = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
    "\n",
    "cfg = AutoConfig.from_pretrained(MODEL, trust_remote_code=True)\n",
    "native_ctx = getattr(cfg, \"max_position_embeddings\", None)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"VRAM(GB):\", round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 1))\n",
    "print(\"Model max_position_embeddings:\", native_ctx)\n",
    "\n",
    "MAX_MODEL_LEN = 19200\n",
    "\n",
    "model = LLM(\n",
    "    model=MODEL,\n",
    "    dtype=\"bfloat16\",\n",
    "    max_model_len=MAX_MODEL_LEN,\n",
    "    gpu_memory_utilization=0.88\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaab1396-2f2f-4691-80b6-4ddf925d8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"–¢—ã ‚Äî –æ—á–µ–Ω—å –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –¢—ã –ø–∏—à–µ—à—å –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º –≤ —Å—Ç–∏–ª–µ –∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–∞.\n",
    "\n",
    "–í—Ö–æ–¥: –∑–∞–ø—Ä–æ—Å, –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (YYYY-MM-DD) –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤–∏–¥–∞:\n",
    "[id] date=YYYY-MM-DD channel(s)=<–∫–∞–Ω–∞–ª1; –∫–∞–Ω–∞–ª2; ...>\n",
    "<—Ç–µ–∫—Å—Ç>\n",
    "–í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–∞—Ç–∏—Ä–æ–≤–∞–Ω—ã –ù–ï –ü–û–ó–ñ–ï –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã.\n",
    "\n",
    "–û–ë–©–ò–ï –ü–†–ê–í–ò–õ–ê:\n",
    "1) –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.\n",
    "2) –ù–µ —É–ø–æ–º–∏–Ω–∞–π –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ([id]).\n",
    "3) –ù–µ –¥–æ–±–∞–≤–ª—è–π –¥–∞—Ç, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π ‚Äú—Å–µ–≥–æ–¥–Ω—è/–≤—á–µ—Ä–∞/–Ω–µ–¥–∞–≤–Ω–æ‚Äù ‚Äî —Ç–æ–ª—å–∫–æ YYYY-MM-DD.\n",
    "4) –õ—é–±—ã–µ —á–∏—Å–ª–∞/—Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è/–ø–æ—Ä–æ–≥–∏/—Ü–∏—Ç–∞—Ç—ã/—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.\n",
    "5) –ö–∞–Ω–∞–ª—ã —É–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ (–≤ —Ç–∞–π–º–ª–∞–π–Ω–µ –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ –±—É–¥–µ—Ç).\n",
    "6) –ï—Å–ª–∏ —Ä—è–¥–æ–º —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–∞—Ç–æ–π –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ‚Äî —á–µ—Å—Ç–Ω–æ —É–∫–∞–∂–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –≤ –ø–æ–¥–±–æ—Ä–∫–µ –∏ —Ä–∞–∑—Ä—ã–≤, –±–µ–∑ –¥–æ–º—ã—Å–ª–æ–≤ ‚Äú—á—Ç–æ —Å–µ–π—á–∞—Å‚Äù.\n",
    "7) –ù–µ–ª—å–∑—è –≤—Å—Ç–∞–≤–ª—è—Ç—å ‚Äú–ø—É—Å—Ç—ã–µ‚Äù –¥–∞—Ç—ã –∏ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ ‚Äú–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö‚Äù.\n",
    "\n",
    "–ö–ê–ö –ü–ò–°–ê–¢–¨ –î–ê–ô–î–ñ–ï–°–¢:\n",
    "- –ù–∞—á–Ω–∏ —Å 2‚Äì4 —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö –£–ù–ò–ö–ê–õ–¨–ù–´–• –¥–∞—Ç –≤ –ø–æ–¥–±–æ—Ä–∫–µ (—ç—Ç–æ ‚Äú–ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è‚Äù).\n",
    "- –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Ñ–∞–∫—Ç–∞ —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫:\n",
    "  ‚Äú–ö–∞–Ω–∞–ª(—ã) (YYYY-MM-DD): ‚Ä¶‚Äù\n",
    "- –ù–µ —Å–º–µ—à–∏–≤–∞–π —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–∏–≥–Ω–∞–ª–æ–≤ –∫–∞–∫ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ: —è–≤–Ω–æ —Ä–∞–∑–ª–∏—á–∞–π\n",
    "  ‚Äú–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å / –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–π –∫—É—Ä—Å / —Ä–∞—Å—á–µ—Ç–Ω—ã–π –∫—É—Ä—Å / –∏–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞ / –ø—Ä–æ–≥–Ω–æ–∑‚Äù.\n",
    "- –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –ø–æ–≤—Ç–æ—Ä—ã ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–π.\n",
    "- –ü–∏—à–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ, –∫–∞–∫ –≤ –Ω–æ–≤–æ—Å—Ç–Ω–æ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ (–±–µ–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –∏ –±–µ–∑ –¥–æ–º—ã—Å–ª–æ–≤).\n",
    "\n",
    "–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê (3 –±–ª–æ–∫–∞):\n",
    "\n",
    "### 1) –ó–∞–ø—Ä–æ—Å –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞\n",
    "* –ó–∞–ø—Ä–æ—Å: ...\n",
    "* –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞: ...\n",
    "\n",
    "### 2) –î–∞–π–¥–∂–µ—Å—Ç\n",
    "–°–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç (8‚Äì20 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –Ω–µ –±–æ–ª–µ–µ!), –∫–∞–∫ –∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç:\n",
    "- ‚Äú–ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è‚Äù: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Å–∞–º—ã–º —Å–≤–µ–∂–∏–º –¥–∞—Ç–∞–º + –∫—Ç–æ —Å–æ–æ–±—â–∏–ª.\n",
    "- –ó–∞—Ç–µ–º –∫–æ—Ä–æ—Ç–∫–æ ‚Äú—Ä–∞–Ω—å—à–µ/–ø—Ä–µ–¥—ã—Å—Ç–æ—Ä–∏—è‚Äù: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –ø–æ –±–æ–ª–µ–µ —Ä–∞–Ω–Ω–∏–º –¥–∞—Ç–∞–º + –∫—Ç–æ —Å–æ–æ–±—â–∏–ª.\n",
    "- –í –∫–æ–Ω—Ü–µ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –≤—ã–≤–æ–¥—ã, –∏—Å—Ö–æ–¥—è –∏–∑ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–µ–π. –ú–æ–∂–Ω–æ –ª–∏ –¥–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏–ª–∏ –Ω–µ—Ç. –ù–∞—Å–∫–æ–ª—å–∫–æ —Ç–µ–º–∞ –≤ —Ü–µ–ª–æ–º –∞–∫—Ç—É–∞–ª—å–Ω–∞—è, —Å–≤–µ–∂–∞—è –∏ –≤–∏—Ä—É—Å–Ω–∞—è.\n",
    "\n",
    "### 3) –¢–∞–π–º–ª–∞–π–Ω (–ø–æ–ª–Ω—ã–π, 1 –¥–∞—Ç–∞ = 1 —Å—Ç—Ä–æ–∫–∞ = 1 —Ñ–∞–∫—Ç, –±–µ–∑ –∫–∞–Ω–∞–ª–æ–≤)\n",
    "–ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –í–°–ï–• –£–ù–ò–ö–ê–õ–¨–ù–´–• –¥–∞—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤ –ø–æ—Ä—è–¥–∫–µ –æ—Ç —Å–∞–º–æ–π —Å—Ç–∞—Ä–æ–π –∫ —Å–∞–º–æ–π –Ω–æ–≤–æ–π (ascending).\n",
    "–û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ = –æ–¥–Ω–∞ (1) –¥–∞—Ç–∞.\n",
    "–û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ = –æ–¥–∏–Ω (1) —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å—É —Ñ–∞–∫—Ç/–∏–∑–º–µ–Ω–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä—ã–π —è–≤–Ω–æ –µ—Å—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö —ç—Ç–æ–π –¥–∞—Ç—ã.\n",
    "\n",
    "–§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏:\n",
    "* YYYY-MM-DD ‚Äî —á—Ç–æ —Å–æ–æ–±—â–∏–ª–∏ / —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å (1 —Ñ–∞–∫—Ç)\n",
    "\n",
    "–ü–†–ê–í–ò–õ–ê –¢–ê–ô–ú–õ–ê–ô–ù–ê (–∫—Ä–∏—Ç–∏—á–Ω–æ):\n",
    "- –í —Ç–∞–π–º–ª–∞–π–Ω–µ –ù–ï –£–ö–ê–ó–´–í–ê–ô –∫–∞–Ω–∞–ª—ã –≤–æ–æ–±—â–µ.\n",
    "- –ù–µ –¥–æ–±–∞–≤–ª—è–π –¥–∞—Ç, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö!\n",
    "- –ù–µ –ø–µ—Ä–µ–Ω–æ—Å–∏ —Ñ–∞–∫—Ç—ã –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏ ‚Äú–ø–æ —Å–º—ã—Å–ª—É‚Äù: –≤ —Å—Ç—Ä–æ–∫–µ –¥–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —ç—Ç–æ–π –¥–∞—Ç—ã!\n",
    "- –ù–∏–∫–∞–∫–∏—Ö –ø—Ä–∏—á–∏–Ω –∏ –≤—ã–≤–æ–¥–æ–≤ ‚Äî —Ç–æ–ª—å–∫–æ ‚Äú—á—Ç–æ —Å–æ–æ–±—â–∏–ª–∏‚Äù!\n",
    "- –ï—Å–ª–∏ –Ω–∞ –æ–¥–Ω—É –¥–∞—Ç—É –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–æ–≤, –≤—ã–±–µ—Ä–∏ –æ–¥–∏–Ω —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (–æ—Å—Ç–∞–ª—å–Ω–æ–µ –æ—Å—Ç–∞–≤—å –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ)!\n",
    "! –ï–°–õ–ò –î–ê–¢–´ –ù–ï–¢ –í–ù–£–¢–†–ò –ö–û–ù–¢–ï–ö–°–¢–ê ‚Äî –ï–Å –ù–ï–õ–¨–ó–Ø –£–ö–ê–ó–´–í–ê–¢–¨. –ï–°–õ–ò –§–ê–ö–¢–ê –ù–ï–¢ –ù–ê –≠–¢–£ –î–ê–¢–£ –í –î–û–ö–£–ú–ï–ù–¢–ê–• ‚Äî –ï–ì–û –ù–ï–õ–¨–ó–Ø –ü–ò–°–ê–¢–¨. !\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def build_rag_context(\n",
    "    query: str,\n",
    "    cand: pd.DataFrame,\n",
    "    anchor_date: str,\n",
    "    k_docs: int = 30,\n",
    "    snip_chars: int = 850,\n",
    "    hot_window_days: int = 30,\n",
    "    hot_ratio: float = 0.8,\n",
    ") -> str:\n",
    "    if cand is None or len(cand) == 0:\n",
    "        return (\n",
    "            f\"–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –î–ê–¢–ê –û–ë–ó–û–†–ê: {anchor_date}\\n\"\n",
    "            f\"–í–û–ü–†–û–°/–ó–ê–ü–†–û–°:\\n{query}\\n\\n\"\n",
    "            f\"–ò–°–¢–û–ß–ù–ò–ö–ò:\\n(–Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)\\n\"\n",
    "        )\n",
    "\n",
    "    c = cand.copy()\n",
    "\n",
    "    date_col = \"date_day\" if \"date_day\" in c.columns else \"date\"\n",
    "    score_col = \"score_temporal\" if \"score_temporal\" in c.columns else \"score_rrf\"\n",
    "\n",
    "    if \"age_days\" not in c.columns:\n",
    "        ad = pd.to_datetime(anchor_date, utc=True).normalize()\n",
    "        dts = pd.to_datetime(c[date_col], errors=\"coerce\", utc=True).dt.normalize()\n",
    "        c[\"age_days\"] = (ad - dts).dt.days.astype(\"float32\")\n",
    "\n",
    "    age = c[\"age_days\"].to_numpy(dtype=np.float32)\n",
    "    hot_mask = (age >= 0) & (age <= float(hot_window_days))\n",
    "\n",
    "    c = c.sort_values(score_col, ascending=False)\n",
    "\n",
    "    n_hot = int(round(k_docs * float(hot_ratio)))\n",
    "    n_hot = max(0, min(n_hot, k_docs))\n",
    "\n",
    "    hot_part = c[hot_mask].head(n_hot)\n",
    "    rest_part = c[~hot_mask].head(k_docs - len(hot_part))\n",
    "    picked = pd.concat([hot_part, rest_part], axis=0)\n",
    "\n",
    "    dd = pd.to_datetime(picked[date_col], errors=\"coerce\", utc=True).dt.normalize()\n",
    "    picked = picked.assign(_doc_day=dd).sort_values([\"_doc_day\", score_col], ascending=[False, False]).head(k_docs)\n",
    "\n",
    "    blocks = []\n",
    "    for i, row in enumerate(picked.itertuples(index=False), start=1):\n",
    "        date_day = getattr(row, \"date_day\", getattr(row, \"date\", \"\"))\n",
    "        if isinstance(date_day, pd.Timestamp):\n",
    "            date_day = date_day.strftime(\"%Y-%m-%d\")\n",
    "        date_day = str(date_day)[:10]\n",
    "\n",
    "        channel = getattr(row, \"channel_name\")\n",
    "        text = getattr(row, \"message\", \"\")\n",
    "\n",
    "        blocks.append(f\"[{i}] date={date_day} channel(s)={channel}\\n document=\" + snippet(str(text), snip_chars))\n",
    "\n",
    "    return (\n",
    "        f\"–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –î–ê–¢–ê –û–ë–ó–û–†–ê: {anchor_date}\\n\"\n",
    "        f\"–í–û–ü–†–û–°/–ó–ê–ü–†–û–°:\\n{query}\\n\\n\"\n",
    "        f\"–ò–°–¢–û–ß–ù–ò–ö–ò:\\n\" + \"\\n\\n\".join(blocks)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a0bfef7-03d2-48bf-8bcb-6910245c8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "import pandas as pd\n",
    "from vllm import SamplingParams\n",
    "\n",
    "JUDGE_SYSTEM = \"\"\"–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–º—É –ø–æ–∏—Å–∫—É –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º (–≤ —Ç.—á. —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–º).\n",
    "\n",
    "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ—Ü–µ–Ω–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å—É. –ó–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –±—ã—Ç—å:\n",
    "- –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–æ–ø–∏–∫–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä \"–∫—É—Ä—Å —Ä—É–±–ª—è –∫ –¥–æ–ª–ª–∞—Ä—É\"),\n",
    "- –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–º –¥—Ä—É–≥–æ–π –Ω–æ–≤–æ—Å—Ç–∏ (—Ç–æ–≥–¥–∞ –∑–∞–ø—Ä–æ—Å –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏–Ω—Ñ–æ–ø–æ–≤–æ–¥).\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ù–∏—á–µ–≥–æ –Ω–µ –¥–æ–¥—É–º—ã–≤–∞–π.\n",
    "\n",
    "–®–∫–∞–ª–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏:\n",
    "2 ‚Äî –¥–æ–∫—É–º–µ–Ω—Ç —è–≤–Ω–æ –ø—Ä–æ —Ç–æ –∂–µ —Å–∞–º–æ–µ: –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ø–∏–∫—É –ò–õ–ò –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–æ—Ç –∂–µ –∏–Ω—Ñ–æ–ø–æ–≤–æ–¥/—Ñ–∞–∫—Ç/—Å–æ–±—ã—Ç–∏–µ, —á—Ç–æ –∏ –∑–∞–ø—Ä–æ—Å.\n",
    "1 ‚Äî –¥–æ–∫—É–º–µ–Ω—Ç —Å–≤—è–∑–∞–Ω –ø–æ —Ç–µ–º–µ/–∫–æ–Ω—Ç–µ–∫—Å—Ç—É, –Ω–æ —ç—Ç–æ –Ω–µ–º–Ω–æ–≥–æ –¥—Ä—É–≥–æ–π –∏–Ω—Ñ–æ–ø–æ–≤–æ–¥, –∏–ª–∏ –ø—Ä–æ —Ç–æ –∂–µ, –Ω–æ –±–µ–∑ –ø—Ä—è–º–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è.\n",
    "0 ‚Äî –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ —Å–æ–≤—Å–µ–º.\n",
    "\n",
    "–ü—Ä–∞–≤–∏–ª–æ —Å—Ç—Ä–æ–≥–æ—Å—Ç–∏:\n",
    "—Å—Ç–∞–≤—å 2 —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–≤—è–∑—å –æ—á–µ–≤–∏–¥–Ω–∞ –ø–æ —Ç–µ–∫—Å—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–∞; –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å—Ç–∞–≤—å 0 –∏–ª–∏ 1.\n",
    "\n",
    "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –∏ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ:\n",
    "{\"relevance\": 0|1|2}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _parse_relevance(text: str) -> int:\n",
    "    text = text.strip()\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        blob = m.group(0)\n",
    "        try:\n",
    "            obj = json.loads(blob)\n",
    "            val = int(obj.get(\"relevance\", 0))\n",
    "            return val if val in (0, 1, 2) else 0\n",
    "        except Exception:\n",
    "            pass\n",
    "    m2 = re.search(r\"relevance\\\"\\s*:\\s*([012])\", text)\n",
    "    if m2:\n",
    "        return int(m2.group(1))\n",
    "    return 0\n",
    "\n",
    "def judge_filter_candidates(\n",
    "    cand: pd.DataFrame,\n",
    "    query: str,\n",
    "    judge_llm,\n",
    "    judge_tokenizer,\n",
    "    *,\n",
    "    keep_threshold: int = 1,     \n",
    "    doc_max_chars: int = 1200,\n",
    "    batch_size: int = 32,\n",
    "    max_out_tokens: int = 40,\n",
    ") -> pd.DataFrame:\n",
    "    if cand is None or len(cand) == 0:\n",
    "        return cand\n",
    "\n",
    "    text_col = \"message\"\n",
    "    channel_col = \"channel_name\"\n",
    "    date_col = \"date_day\"\n",
    "\n",
    "    prompts = []\n",
    "    for _, row in cand.iterrows():\n",
    "        doc = str(row[text_col])[:doc_max_chars]\n",
    "        ch = str(row[channel_col]) if channel_col else \"\"\n",
    "        dt = str(row[date_col]) if date_col else \"\"\n",
    "\n",
    "        user_msg = (\n",
    "            f\"–ó–ê–ü–†–û–°:\\n{query}\\n\\n\"\n",
    "            f\"–ö–ê–ù–î–ò–î–ê–¢:\\n\"\n",
    "            f\"channel={ch}\\n\"\n",
    "            f\"date={dt}\\n\"\n",
    "            f\"text:\\n{doc}\\n\"\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": JUDGE_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ]\n",
    "        prompt = judge_tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    sampling = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        max_tokens=max_out_tokens,\n",
    "    )\n",
    "\n",
    "    relevances = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        outs = judge_llm.generate(batch_prompts, sampling)\n",
    "        for o in outs:\n",
    "            txt = o.outputs[0].text\n",
    "            relevances.append(_parse_relevance(txt))\n",
    "\n",
    "    out_df = cand.copy()\n",
    "    out_df[\"judge_relevance\"] = relevances\n",
    "\n",
    "    filtered = out_df[out_df[\"judge_relevance\"] >= keep_threshold].copy()\n",
    "    filtered.reset_index(drop=True, inplace=True)\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b04c688-b520-422b-ab98-275c68d10ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# @torch.inference_mode()\n",
    "# def rag_summarize(sum_model, sum_tokenizer, query: str, cand: pd.DataFrame, anchor_date, \n",
    "#                   k_docs: int = 25, snip_chars: int = 900, max_new_tokens: int = 2000) -> str:\n",
    "    \n",
    "#     user = build_rag_context(query, cand, anchor_date=anchor_date, k_docs=k_docs, snip_chars=snip_chars)\n",
    "#     print(\"built context...\")\n",
    "    \n",
    "#     messages = [\n",
    "#         {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "#         {\"role\": \"user\", \"content\": user},\n",
    "#     ]\n",
    "#     prompt = sum_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "#     enc = sum_tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(sum_model.device)\n",
    "\n",
    "#     out_ids = sum_model.generate(\n",
    "#         **enc,\n",
    "#         max_new_tokens=max_new_tokens,\n",
    "#         do_sample=False,\n",
    "#         eos_token_id=sum_tokenizer.eos_token_id,\n",
    "#         pad_token_id=sum_tokenizer.eos_token_id,\n",
    "#     )\n",
    "#     prompt_len = int(enc[\"attention_mask\"][0].sum().item())\n",
    "    \n",
    "#     return sum_tokenizer.decode(out_ids[0][prompt_len:], skip_special_tokens=True).strip(), user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79a6f6c0-27c0-48ec-b32f-94dcc09ce244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "def rag_summarize(\n",
    "    sum_model,\n",
    "    sum_tokenizer,\n",
    "    query: str,\n",
    "    cand: pd.DataFrame,\n",
    "    anchor_date,\n",
    "    k_docs: int = 25,\n",
    "    snip_chars: int = 900,\n",
    "    max_new_tokens: int = 2000,\n",
    "    hot_window_days: int = 30,\n",
    "    hot_ratio: float = 0.8,\n",
    "):\n",
    "    user = build_rag_context(\n",
    "        query=query,\n",
    "        cand=cand,\n",
    "        anchor_date=str(anchor_date),\n",
    "        k_docs=k_docs,\n",
    "        snip_chars=snip_chars,\n",
    "        hot_window_days=hot_window_days,\n",
    "        hot_ratio=hot_ratio,\n",
    "    )\n",
    "    print(\"built context...\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "    ]\n",
    "\n",
    "    prompt = sum_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    sampling = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        max_tokens=max_new_tokens,\n",
    "    )\n",
    "\n",
    "    result = sum_model.generate([prompt], sampling)[0]\n",
    "    text = result.outputs[0].text.strip()\n",
    "    return text, user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "382a7922-4c1b-4d3f-bbd7-95152e4842e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_hybrid(\n",
    "    df: pd.DataFrame,\n",
    "    index,\n",
    "    encoder,\n",
    "    bm25,\n",
    "    tokenize_fn,\n",
    "    query: str,\n",
    "    k_retrieve: int = 50,\n",
    "    topN_each: int = 500,\n",
    "    k_docs: int = 25,\n",
    "    snip_chars: int = 1500,\n",
    "    max_new_tokens: int = 2000,\n",
    "    anchor_date: str = \"2025-09-04\",\n",
    "    max_window_days: int | None = 365,\n",
    "    w_time: float = 0.5,\n",
    "    w_channel: float | None = None,\n",
    "    hot_window_days: int = 30,\n",
    "    hot_ratio: float = 0.8,\n",
    "    sum_model=None,\n",
    "    sum_tokenizer=None,\n",
    "    judge_llm=None,\n",
    "    judge_tokenizer=None,\n",
    "    judge_keep_threshold: int = 1,\n",
    "    judge_batch_size: int = 32,\n",
    "):\n",
    "    cand = hybrid_retrieve_rrf(\n",
    "        df=df,\n",
    "        index=index,\n",
    "        encoder=encoder,\n",
    "        bm25=bm25,\n",
    "        tokenize_fn=tokenize_fn,\n",
    "        query=query,\n",
    "        k=k_retrieve,\n",
    "        topN_each=topN_each,\n",
    "        k_rrf=60,\n",
    "        w_dense=1.0,\n",
    "        w_bm25=1.0,\n",
    "        anchor_date=anchor_date,\n",
    "        max_window_days=max_window_days,\n",
    "        w_time=w_time,\n",
    "        w_channel=w_channel,\n",
    "    )\n",
    "    print(\"retrieval done...\")\n",
    "    cand_before = cand\n",
    "\n",
    "    cand_clusters = None\n",
    "    members = None\n",
    "    if cand is not None and len(cand) > 0 and encoder is not None:\n",
    "        text_col = \"message\"\n",
    "        cand, cand_clusters, members = dedup_cluster_candidates_time(\n",
    "            cand=cand,\n",
    "            encoder=encoder,\n",
    "            text_col=text_col,\n",
    "            score_col=\"score_rrf\",\n",
    "            sim_threshold=0.95,\n",
    "            knn=30,\n",
    "            keep_per_cluster=1,\n",
    "            mask_numbers=False,\n",
    "            max_day_diff=1,\n",
    "            overwrite_channel=True,\n",
    "        )\n",
    "    print(\"clustering done...\")\n",
    "\n",
    "    cand_after_dedup = cand\n",
    "    if (\n",
    "        judge_llm is not None\n",
    "        and judge_tokenizer is not None\n",
    "        and cand is not None\n",
    "        and len(cand) > 0\n",
    "    ):\n",
    "        cand = judge_filter_candidates(\n",
    "            cand=cand,\n",
    "            query=query,\n",
    "            judge_llm=judge_llm,\n",
    "            judge_tokenizer=judge_tokenizer,\n",
    "            keep_threshold=judge_keep_threshold,\n",
    "            doc_max_chars=snip_chars,\n",
    "            batch_size=judge_batch_size,\n",
    "        )\n",
    "    print(\"filtering done...\")\n",
    "\n",
    "    if sum_model is None or sum_tokenizer is None:\n",
    "        ctx = build_rag_context(\n",
    "            query,\n",
    "            cand,\n",
    "            anchor_date=anchor_date,\n",
    "            k_docs=min(k_docs, len(cand)) if cand is not None else 0,\n",
    "            snip_chars=snip_chars,\n",
    "            hot_window_days=hot_window_days,\n",
    "            hot_ratio=hot_ratio,\n",
    "        )\n",
    "        return {\n",
    "            \"context\": ctx,\n",
    "            \"candidates\": cand_before,\n",
    "            \"candidates_dedup\": cand_after_dedup,\n",
    "            \"candidates_filtered\": cand,\n",
    "            \"members\": members,\n",
    "            \"clusters\": cand_clusters,\n",
    "            \"summary\": \"No LLM\",\n",
    "        }\n",
    "\n",
    "    summary, ctx = rag_summarize(\n",
    "        sum_model,\n",
    "        sum_tokenizer,\n",
    "        query,\n",
    "        cand,\n",
    "        k_docs=min(k_docs, len(cand)) if cand is not None else 0,\n",
    "        snip_chars=snip_chars,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        anchor_date=anchor_date,\n",
    "        hot_window_days=hot_window_days,\n",
    "        hot_ratio=hot_ratio,\n",
    "    )\n",
    "    print(\"summary done...\")\n",
    "\n",
    "    return {\n",
    "        \"context\": ctx,\n",
    "        \"summary\": summary,\n",
    "        \"candidates\": cand_before,\n",
    "        \"candidates_dedup\": cand_after_dedup,\n",
    "        \"candidates_filtered\": cand,\n",
    "        \"members\": members,\n",
    "        \"clusters\": cand_clusters,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453b4b7-8475-4e75-87bf-3fd23950401c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4cdc31c-ad49-4c99-bab8-8d16d73c7f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval done...\n",
      "clustering done...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbc06218a6c412c902652fd49c4fb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001abf773a324b87ad4c2514cff62d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1310c575a1246339abffb22d158f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ddcb5f992d456eaea20a59f344d6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7408dc9f8af42ebbbc1f979bd1379b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c6bf547c474b369b13b9c06a77f351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c091c718148f9a64c3d35bc9028d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff93b527d0f64e07983ab08226f2e717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/28 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering done...\n",
      "built context...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce65803ac4b14c35974eedbf7e71a858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a415ac959cc349309a5777c5933ed5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary done...\n"
     ]
    }
   ],
   "source": [
    "q = \"–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞\"\n",
    "\n",
    "out = run_rag_hybrid(\n",
    "    df=df,\n",
    "    index=index,\n",
    "    encoder=encoder,\n",
    "    bm25=bm25,\n",
    "    tokenize_fn=tokenize_ru,\n",
    "    query=q,\n",
    "    k_retrieve=150,\n",
    "    topN_each=2000,\n",
    "    k_docs=30,\n",
    "    snip_chars=1000,\n",
    "    max_new_tokens=3000,\n",
    "    anchor_date=\"2025-09-04\",\n",
    "    max_window_days=365,\n",
    "    w_time=0.6,\n",
    "    w_channel=None,\n",
    "    hot_window_days=30,\n",
    "    hot_ratio=0.8,\n",
    "    sum_model=model,\n",
    "    sum_tokenizer=tokenizer,\n",
    "    judge_llm=model,\n",
    "    judge_tokenizer=tokenizer,\n",
    "    judge_keep_threshold=1,\n",
    "    judge_batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8f8574b-ad55-46f5-b75f-9c8ef1738f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 1) –ó–∞–ø—Ä–æ—Å –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞\n",
       "* –ó–∞–ø—Ä–æ—Å: –ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞\n",
       "* –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞: 2025-09-04\n",
       "\n",
       "### 2) –î–∞–π–¥–∂–µ—Å—Ç\n",
       "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è, 2025-09-04, –ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞ –∏ –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏ —Å–æ–æ–±—â–∏–ª–∏, —á—Ç–æ –∫—É—Ä—Å —Ä—É–±–ª—è –±—É–¥–µ—Ç –∫—Ä–µ–ø—á–µ, —á–µ–º –æ–∂–∏–¥–∞–ª–æ—Å—å, –∏ –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –¥–æ–ª–ª–∞—Ä –ø–æ 94,3 —Ä—É–±–ª—è –≤ 2025 –≥–æ–¥—É, 100 —Ä—É–±–ª–µ–π –≤ 2026 –≥–æ–¥—É –∏ 103,5 —Ä—É–±–ª—è –≤ 2027 –≥–æ–¥—É. –¢–∞–∫–∂–µ –ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞ –∏ –†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏ –æ—Ç–º–µ—Ç–∏–ª–∏, —á—Ç–æ –ì—Ä–µ—Ñ –æ–∂–∏–¥–∞–µ—Ç –æ—Å–ª–∞–±–ª–µ–Ω–∏—è –∫—É—Ä—Å–∞ —Ä—É–±–ª—è –¥–æ 85-90 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä –∫ –∫–æ–Ω—Ü—É 2025 –≥–æ–¥–∞. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¶–ë –Ω–∞ 2025-09-04 —Å–æ—Å—Ç–∞–≤–∏–ª 81 —Ä—É–±–ª—å –∑–∞ –¥–æ–ª–ª–∞—Ä, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –º–∞–∫—Å–∏–º—É–º–æ–º —Å 1 –∞–≤–≥—É—Å—Ç–∞.\n",
       "\n",
       "–†–∞–Ω–µ–µ, 2025-09-02, –ë–ª—É–º–±–µ—Ä–≥ –∏ Forbes Russia —Å–æ–æ–±—â–∏–ª–∏, —á—Ç–æ –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å 100 —Ä—É–±–ª–µ–π —É–∂–µ –∫ —è–Ω–≤–∞—Ä—é, –∏ —á—Ç–æ –≤ —ç—Ç–æ–º –≥–æ–¥—É –¥–æ–ª–ª–∞—Ä –≤ —è–Ω–≤–∞—Ä–µ –Ω–∞ –ø–∏–∫–µ —Å—Ç–æ–∏–ª 113,7 —Ä—É–±–ª—è, –∞ –Ω–∞ –º–∏–Ω–∏–º—É–º–µ –≤ –∏—é–ª–µ ‚Äî 73,9 —Ä—É–±–ª—è. –í 2025-08-31, –ë–ª—É–º–±–µ—Ä–≥ –∏ –ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞ —Å–æ–æ–±—â–∏–ª–∏, —á—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–π –∫—É—Ä—Å —Ä—É–±–ª—è –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å 24,5 –∑–∞ –¥–æ–ª–ª–∞—Ä, –∏ —á—Ç–æ —Ä—É–±–ª—å —Å–Ω–æ–≤–∞ –æ–∫–∞–∑–∞–ª—Å—è –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –≤–∞–ª—é—Ç –≤ –º–∏—Ä–µ.\n",
       "\n",
       "–¢–µ–º–∞ –∫—É—Ä—Å–∞ –¥–æ–ª–ª–∞—Ä–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏ –≤–∏—Ä—É—Å–Ω–æ–π, —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏ –æ—Ü–µ–Ω–æ–∫. –û–¥–Ω–∞–∫–æ, –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥, —á—Ç–æ –∫—É—Ä—Å —Ä—É–±–ª—è –æ—Å—Ç–∞–µ—Ç—Å—è –∫—Ä–µ–ø–∫–∏–º, –Ω–æ —ç–∫—Å–ø–µ—Ä—Ç—ã –æ–∂–∏–¥–∞—é—Ç –µ–≥–æ –æ—Å–ª–∞–±–ª–µ–Ω–∏—è –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è.\n",
       "\n",
       "### 3) –¢–∞–π–º–ª–∞–π–Ω\n",
       "* 2025-09-04 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Å–æ—Å—Ç–∞–≤–∏–ª 81 —Ä—É–±–ª—å\n",
       "* 2025-09-04 ‚Äî –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ 2025-2027 –≥–æ–¥—ã\n",
       "* 2025-09-04 ‚Äî –ì—Ä–µ—Ñ –æ–∂–∏–¥–∞–µ—Ç –æ—Å–ª–∞–±–ª–µ–Ω–∏—è –∫—É—Ä—Å–∞ —Ä—É–±–ª—è –¥–æ 85-90 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä –∫ –∫–æ–Ω—Ü—É 2025 –≥–æ–¥–∞\n",
       "* 2025-09-02 ‚Äî –ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å 100 —Ä—É–±–ª–µ–π —É–∂–µ –∫ —è–Ω–≤–∞—Ä—é\n",
       "* 2025-09-01 ‚Äî –ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Å –º–∞—è –ø–æ –∞–≤–≥—É—Å—Ç –¥–µ—Ä–∂–∏—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ 78‚Äì80 —Ä—É–±–ª–µ–π\n",
       "* 2025-08-31 ‚Äî –†–µ–∞–ª—å–Ω—ã–π –∫—É—Ä—Å —Ä—É–±–ª—è –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å 24,5 –∑–∞ –¥–æ–ª–ª–∞—Ä\n",
       "* 2025-08-18 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ 19 –∞–≤–≥—É—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–∏–ª 80.4256 —Ä—É–±–ª—è\n",
       "* 2025-08-14 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ 15 –∞–≤–≥—É—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–∏–ª 79.7653 —Ä—É–±–ª—è\n",
       "* 2025-08-07 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ 8 –∞–≤–≥—É—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–∏–ª 79.3847 —Ä—É–±–ª—è\n",
       "* 2025-07-28 ‚Äî –°–≤–µ–∂–∏–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ—Ç –¶–ë –æ–∫–∞–∑–∞–ª—Å—è –º–µ–Ω—å—à–µ –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–≥–æ –Ω–∞ –ø–æ–ª—Ç–æ—Ä–∞ —Ä—É–±–ª—è\n",
       "* 2025-06-30 ‚Äî –ò–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 97 –ø—É–Ω–∫—Ç–æ–≤ –≤–ø–µ—Ä–≤—ã–µ —Å –º–∞—Ä—Ç–∞ 2022 –≥–æ–¥–∞\n",
       "* 2025-06-20 ‚Äî –†–∞–≤–Ω–æ–≤–µ—Å–Ω—ã–º –∫—É—Ä—Å–æ–º —è–≤–ª—è–µ—Ç—Å—è –≤—ã—à–µ 100 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä\n",
       "* 2025-06-19 ‚Äî –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –≤ —Ç–µ–∫—É—â–µ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ —Ä–∞–π–æ–Ω–µ 100 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä\n",
       "* 2025-06-12 ‚Äî –ò–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –¥–æ –º–∏–Ω–∏–º—É–º–∞ —Å –≤–µ—Å–Ω—ã 2022 –≥–æ–¥–∞\n",
       "* 2025-05-29 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ—Ç –¶–ë –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 79 —Ä—É–±–ª–µ–π\n",
       "* 2025-05-21 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ 22 –º–∞—è —Å–æ—Å—Ç–∞–≤–∏–ª 79,75 —Ä—É–±–ª—è\n",
       "* 2025-04-21 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 81 —Ä—É–±–ª—è\n",
       "* 2025-04-14 ‚Äî –¶–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫ –ø–æ–Ω–∏–∑–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 1 —Ä—É–±–ª—å\n",
       "* 2025-03-18 ‚Äî –í–Ω–µ–±–∏—Ä–∂–µ–≤–æ–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 81 —Ä—É–±–ª—è\n",
       "* 2025-03-17 ‚Äî –†–∞—Å—á–µ—Ç–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —É–ø–∞–ª –Ω–∏–∂–µ 83 —Ä—É–±–ª–µ–π\n",
       "* 2025-03-11 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –¥–æ 86 —Ä—É–±–ª–µ–π\n",
       "* 2024-12-24 ‚Äî –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —É–ø–∞–ª –Ω–∏–∂–µ 100 —Ä—É–±–ª–µ–π\n",
       "* 2024-12-06 ‚Äî –¶–ë –ø–æ–Ω–∏–∑–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∏–∂–µ 100, –µ–≤—Ä–æ ‚Äî –Ω–∏–∂–µ 107 —Ä—É–±–ª–µ–π\n",
       "* 2024-11-27 ‚Äî –ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –ø–µ—Ä–µ–≤–∞–ª–∏–ª –∑–∞ 111 —Ä—É–±–ª–µ–π\n",
       "* 2024-11-14 ‚Äî –ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Ç–µ–ø–µ—Ä—å —Å—Ç–æ–∏—Ç –≤—ã—à–µ 100 —Ä—É–±–ª–µ–π"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "import re\n",
    "\n",
    "def show_summary(summary: str):\n",
    "    if summary is None:\n",
    "        display(HTML(\"<b>summary is None</b>\"))\n",
    "        return\n",
    "\n",
    "    s = str(summary)\n",
    "    s = s.replace(\"\\\\n\", \"\\n\") \n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s).strip()\n",
    "\n",
    "    display(Markdown(s))\n",
    "\n",
    "show_summary(out[\"summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "281df5a5-9cb8-4de9-b90c-0576d4d34df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context chars: 8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2745"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"context chars:\", len(out[\"context\"]))\n",
    "len(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4e25602-c922-4041-abc4-2fd0f98f6c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "–ê–ö–¢–£–ê–õ–¨–ù–ê–Ø –î–ê–¢–ê –û–ë–ó–û–†–ê: 2025-09-04\n",
       "–í–û–ü–†–û–°/–ó–ê–ü–†–û–°:\n",
       "–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞\n",
       "\n",
       "–ò–°–¢–û–ß–ù–ò–ö–ò:\n",
       "[1] date=2025-09-04 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–ö—É—Ä—Å —Ä—É–±–ª—è –±—É–¥–µ—Ç –∫—Ä–µ–ø—á–µ, —á–µ–º –æ–∂–∏–¥–∞–ª–æ—Å—å, –∏ ¬´–Ω–∞–º –≤—Å–µ–º, –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–∏–¥–µ—Ç—Å—è –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è¬ª ‚Äî –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è. –ï—â—ë –≤ –∞–ø—Ä–µ–ª–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–ª–æ –¥–æ–ª–ª–∞—Ä –ø–æ 94,3 —Ä—É–±–ª—è –≤ 2025 –≥–æ–¥—É, –≤ 2026-–º ‚Äî 100 —Ä—É–±–ª–µ–π, 103,5 —Ä—É–±–ª—è –≤ 2027-–º. @bankrollo\n",
       "\n",
       "[2] date=2025-09-04 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–ö—É—Ä—Å —Ä—É–±–ª—è –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è –±—É–¥–µ—Ç –∫—Ä–µ–ø—á–µ –ø—Ä–µ–∂–Ω–∏—Ö –æ—Ü–µ–Ω–æ–∫, –≤—Å–µ–º –ø—Ä–∏–¥–µ—Ç—Å—è –∫ —ç—Ç–æ–º—É –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è, –∑–∞—è–≤–∏–ª –≤ —Ä–∞–º–∫–∞—Ö –í–≠–§ –†–µ—à–µ—Ç–Ω–∏–∫–æ–≤. –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏\n",
       "\n",
       "[3] date=2025-09-04 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–î–æ–ª–ª–∞—Ä –ø–æ–¥–Ω—è–ª—Å—è –¥–æ 81 —Ä—É–±–ª—è –ø–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º—É –∫—É—Ä—Å—É –¶–ë –≤–ø–µ—Ä–≤—ã–µ —Å 1 –∞–≤–≥—É—Å—Ç–∞. @bankrollo\n",
       "\n",
       "[4] date=2025-09-04 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–ì—Ä–µ—Ñ –æ–∂–∏–¥–∞–µ—Ç –æ—Å–ª–∞–±–ª–µ–Ω–∏—è –∫—É—Ä—Å–∞ —Ä—É–±–ª—è –¥–æ 85-90 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä –∫ –∫–æ–Ω—Ü—É 2025 –≥–æ–¥–∞. \"–ù–∞ –º–æ–π –≤–∑–≥–ª—è–¥, —Ä—É–±–ª—å –ø–µ—Ä–µ—É–∫—Ä–µ–ø–∏–ª—Å—è —Å–µ–π—á–∞—Å, –∏ –≤—Ä—è–¥ –ª–∏ —Å—Ç–æ–∏—Ç –æ–∂–∏–¥–∞—Ç—å —É–∫—Ä–µ–ø–ª–µ–Ω–∏—è —Ä—É–±–ª—è. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —á—Ç–æ-–ª–∏–±–æ —Å–ª–æ–∂–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –º–Ω–æ–≥–æ—Ñ–∞–∫—Ç–æ—Ä–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è. –ù–æ —Ç–æ, —á—Ç–æ –º—ã –≤–∏–¥–∏–º —Å–µ–≥–æ–¥–Ω—è, –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏, –∫–æ—Ç–æ—Ä–∞—è —Å–µ–π—á–∞—Å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç, –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –æ—Å–ª–∞–±–ª–µ–Ω–∏—é —Ä—É–±–ª—è\", - —Å–∫–∞–∑–∞–ª –ì—Ä–µ—Ñ –≤ –∏–Ω—Ç–µ—Ä–≤—å—é –ù–∞–∏–ª–µ –ê—Å–∫–µ—Ä-–∑–∞–¥–µ –Ω–∞ —Ç–µ–ª–µ–∫–∞–Ω–∞–ª–µ \"–†–æ—Å—Å–∏—è 1\". –ü—Ä–∏ —ç—Ç–æ–º –æ–Ω –∑–∞—Ç—Ä—É–¥–Ω–∏–ª—Å—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å –∫—É—Ä—Å –Ω–∞ —Å—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–π –ø–µ—Ä–∏–æ–¥. \"–í –±–ª–∏–∂–∞–π—à–∏–µ —Ç—Ä–∏ –≥–æ–¥–∞, –∫–æ–Ω–µ—á–Ω–æ, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ, –Ω–æ, –æ–ø—è—Ç—å, –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∏, –ø–æ–∫–∞ —è –Ω–µ –≤–∏–∂—É —á–µ–≥–æ-—Ç–æ, —á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å–∏–ª—å–Ω–æ–º—É —É–∫—Ä–µ–ø–ª–µ–Ω–∏—é —Ä—É–±–ª—è\", - –∑–∞—è–≤–∏–ª –±–∞–Ω–∫–∏—Ä. –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏\n",
       "\n",
       "[5] date=2025-09-02 channel(s)=–ë–ª—É–º–±–µ—Ä–≥\n",
       " document=–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏—á—å 100 —Ä—É–±–ª–µ–π —É–∂–µ –∫ —è–Ω–≤–∞—Ä—é, –∑–∞—è–≤–∏–ª –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ë–∞—Ö—Ç–∏–Ω. @bIoombusiness\n",
       "\n",
       "[6] date=2025-09-02 channel(s)=Forbes Russia\n",
       " document=–í —ç—Ç–æ–º –≥–æ–¥—É –¥–æ–ª–ª–∞—Ä –≤ —è–Ω–≤–∞—Ä–µ –Ω–∞ –ø–∏–∫–µ —Å—Ç–æ–∏–ª 113,7 —Ä—É–±–ª—è, –∞ –Ω–∞ –º–∏–Ω–∏–º—É–º–µ –≤ –∏—é–ª–µ ‚Äî 73,9 —Ä—É–±–ª—è. –î–æ—à–ª–æ –¥–æ —Ç–æ–≥–æ, —á—Ç–æ Bloomberg –Ω–∞–∑–≤–∞–ª —Ä–æ—Å—Å–∏–π—Å–∫—É—é –≤–∞–ª—é—Ç—É —Å–∞–º–æ–π –ª—É—á—à–µ–π –≤ 2025 –≥–æ–¥—É. –ï—â–µ –±—ã, —Ä—É–±–ª—å —É–∫—Ä–µ–ø–∏–ª—Å—è —Å –Ω–∞—á–∞–ª–∞ –≥–æ–¥–∞ –Ω–∞ 30%. –° —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–æ—Å—Å–∏—è–Ω–∏–Ω–∞, —Å –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –≤–∞–ª—é—Ç–æ–π –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á—Ç–æ-—Ç–æ –Ω–µ–æ–±—ã—á–Ω–æ–µ –∏ –Ω–µ—è—Å–Ω–æ, –∫–∞–∫–æ–≤ –µ–µ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π –∫—É—Ä—Å, —Å—á–∏—Ç–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –£–ö ¬´–ê—Ä–∏–ö–∞–ø–∏—Ç–∞–ª¬ª –ê–ª–µ–∫—Å–µ–π –¢—Ä–µ—Ç—å—è–∫–æ–≤. –ö–∞–∫–∏–º –≤–æ–æ–±—â–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π –∫—É—Ä—Å —Ä—É–±–ª—è? –ß—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å, –Ω—É–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫–∏–º –±—ã–ª –∫—É—Ä—Å –≤ –ø–µ—Ä–∏–æ–¥ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏, —Å–¥–µ–ª–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É —Å —É—á–µ—Ç–æ–º –∏–Ω—Ñ–ª—è—Ü–∏–∏ –∏ —Ç–µ—Ö —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–∏–∑–æ—à–ª–∏ –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è. –í –Ω–∞—á–∞–ª–µ 2015 –≥–æ–¥–∞ –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –≤ —Ä—É–±–ª—è—Ö –º–æ–∂–Ω–æ –Ω–∞–∑–≤–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º. –í —Ç–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –ø—è—Ç–∏ –ª–µ—Ç (–≤–ø–ª–æ—Ç—å –¥–æ –Ω–∞—á–∞–ª–∞ –ø–∞–Ω–¥–µ–º–∏–∏ –∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å–∞ –≤ 2020 –≥–æ–¥—É) –∫—É—Ä—Å –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –≤—Ä–µ–º–µ–Ω–∏ –æ—Å—Ç–∞–≤–∞–ª—Å—è –≤ —Ä–∞–º–∫–∞—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–∑–∫–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 60‚Äì70 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä –°–®–ê. –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —ç—Ç–æ—Ç –∫—É—Ä—Å –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—É—é —Ä—É–±–ª–µ–≤—É—é –∏–Ω—Ñ–ª—è—Ü–∏—é. –°–æ–≥–ª–∞—Å–Ω–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –¥\n",
       "\n",
       "[7] date=2025-09-01 channel(s)=Forbes Russia\n",
       " document=–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Å –º–∞—è –ø–æ –∞–≤–≥—É—Å—Ç –¥–µ—Ä–∂–∏—Ç—Å—è –Ω–∞ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–º –¥–ª—è –Ω–∞—Å–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ 78‚Äì80 —Ä—É–±–ª–µ–π. –°–∏—Ç—É–∞—Ü–∏—è —á–µ–º-—Ç–æ –ø–æ—Ö–æ–∂–∞ –Ω–∞ 2022 –≥–æ–¥, –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ –†–æ—Å—Å–∏–µ–π ¬´—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏–∏¬ª–∏ —à–æ–∫–∞ –Ω–∞ –≤–∞–ª—é—Ç–Ω–æ–º —Ä—ã–Ω–∫–µ –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Å –∏—é–ª—è –ø–æ –¥–µ–∫–∞–±—Ä—å –Ω–∞—Ö–æ–¥–∏–ª—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ 60 —Ä—É–±–ª–µ–π –∏–∑-–∑–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –≤–æ –≤–Ω–µ—à–Ω–µ–π —Ç–æ—Ä–≥–æ–≤–ª–µ ‚Äî –∏–º–ø–æ—Ä—Ç –æ–±–≤–∞–ª–∏–ª—Å—è, —Å–ø—Ä–æ—Å–∞ –Ω–∞ –≤–∞–ª—é—Ç—É –Ω–µ –±—ã–ª–æ. –ù–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≥–æ–¥–∞ —ç–∫—Å–ø–µ—Ä—Ç—ã –≥–æ–≤–æ—Ä–∏–ª–∏, —á—Ç–æ –∫—É—Ä—Å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ—Ç–æ–∫–∞–º–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏ –∏–º–ø–æ—Ä—Ç–∞. –û–¥–Ω–∞–∫–æ –≤–æ II –∫–≤–∞—Ä—Ç–∞–ª–µ —ç—Ç–æ–≥–æ –≥–æ–¥–∞ —ç–∫—Å–ø–æ—Ä—Ç —Å–Ω–∏–∑–∏–ª—Å—è, –∏–º–ø–æ—Ä—Ç –ø–æ–¥—Ä–æ—Å, –Ω–æ —ç—Ç–æ –Ω–∏–∫–∞–∫ –Ω–µ –æ—Ç—Ä–∞–∑–∏–ª–æ—Å—å –Ω–∞ –≤–∞–ª—é—Ç–Ω–æ–º —Ä—ã–Ω–∫–µ. –í–æ–∑–º–æ–∂–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ ‚Äî –±–æ–ª—å—à–µ –ø–æ–ª–æ–≤–∏–Ω—ã —Ä–∞—Å—á–µ—Ç–æ–≤ –ø–æ –≤–Ω–µ—à–Ω–µ–π —Ç–æ—Ä–≥–æ–≤–ª–µ –∏–¥–µ—Ç –≤ —Ä—É–±–ª—è—Ö, –∞ –∫—É—Ä—Å —Ç–µ—Ä—è–µ—Ç —Å–≤—è–∑—å —Å —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å—é. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Ç–æ–º, –ø–æ—á–µ–º—É –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è –≤–æ–ø—Ä–µ–∫–∏ —Ä–æ—Å—Ç—É –∏–º–ø–æ—Ä—Ç–∞ –∏ —á—Ç–æ –±—É–¥–µ—Ç —Å –Ω–∏–º –¥–∞–ª—å—à–µ ‚Äî —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —Å–∞–π—Ç–µ üì∏: –§–æ—Ç–æ Getty Images\n",
       "\n",
       "[8] date=2025-08-31 channel(s)=–ë–ª—É–º–±–µ—Ä–≥\n",
       " document=–†–µ–∞–ª—å–Ω—ã–π –∫—É—Ä—Å —Ä—É–±–ª—è –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å 24,5 –∑–∞ –¥–æ–ª–ª–∞—Ä, —Å—á–∏—Ç–∞—é—Ç —ç–∫—Å–ø–µ—Ä—Ç—ã. –†–æ—Å—Å–∏–π—Å–∫–∞—è –≤–∞–ª—é—Ç–∞ –Ω–∞–∑–≤–∞–Ω–∞ –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –Ω–µ–¥–æ–æ—Ü–µ–Ω—ë–Ω–Ω—ã—Ö –≤ –º–∏—Ä–µ. @bIoombusiness\n",
       "\n",
       "[9] date=2025-08-31 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–†—É–±–ª—å —Å–Ω–æ–≤–∞ –æ–∫–∞–∑–∞–ª—Å—è –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –Ω–µ–¥–æ–æ—Ü–µ–Ω–µ–Ω–Ω—ã—Ö –≤–∞–ª—é—Ç –≤ –º–∏—Ä–µ. –ü–æ –∏–Ω–¥–µ–∫—Å—É –±–∏–≥–º–∞–∫–∞ –µ–≥–æ –∫—É—Ä—Å –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å 24,5 —Ä—É–±–ª—è –∑–∞ –¥–æ–ª–ª–∞—Ä ‚Äî –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏. @bankollo\n",
       "\n",
       "[10] date=2025-08-18 channel(s)=–°–∏–≥–Ω–∞–ª—ã –†–¶–ë\n",
       " document=üè¶ –¶–ë —É—Å—Ç–∞–Ω–æ–≤–∏–ª –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –Ω–∞ 19 –∞–≤–≥—É—Å—Ç–∞: USD: 80.4256 (+0.50%) EUR: 94.0884 (+0.40%) CNY: 11.1547 (+0.42%)\n",
       "\n",
       "[11] date=2025-08-14 channel(s)=–°–∏–≥–Ω–∞–ª—ã –†–¶–ë\n",
       " document=üè¶ –¶–ë —É—Å—Ç–∞–Ω–æ–≤–∏–ª –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –Ω–∞ 15 –∞–≤–≥—É—Å—Ç–∞: USD: 79.7653 (+0.20%) EUR: 93.0588 (-0.35%) CNY: 11.0940 (+0.24%)\n",
       "\n",
       "[12] date=2025-08-07 channel(s)=–°–∏–≥–Ω–∞–ª—ã –†–¶–ë\n",
       " document=üè¶ –¶–ë —É—Å—Ç–∞–Ω–æ–≤–∏–ª –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –∫—É—Ä—Å—ã –≤–∞–ª—é—Ç –Ω–∞ 8 –∞–≤–≥—É—Å—Ç–∞: USD: 79.3847 (-1.00%) EUR: 92.6636 (-0.36%) CNY: 11.0170 (-0.89%)\n",
       "\n",
       "[13] date=2025-07-28 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–°–≤–µ–∂–∏–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ—Ç –¶–ë –æ–∫–∞–∑–∞–ª—Å—è –º–µ–Ω—å—à–µ –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–≥–æ –Ω–∞ –ø–æ–ª—Ç–æ—Ä–∞ —Ä—É–±–ª—è. @bankrollo\n",
       "\n",
       "[14] date=2025-06-30 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–ò–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∏–π –∫—É—Ä—Å –∫ –≤–∞–ª—é—Ç–∞–º —à–µ—Å—Ç–∏ —Å—Ç—Ä–∞–Ω - —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ –°–®–ê, —Å–µ–≥–æ–¥–Ω—è –æ–ø—É—Å–∫–∞–ª—Å—è –Ω–∏–∂–µ 97 –ø—É–Ω–∫—Ç–æ–≤ –≤–ø–µ—Ä–≤—ã–µ —Å –º–∞—Ä—Ç–∞ 2022-–≥–æ –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏ / –í—Å–µ –Ω–∞—à–∏ –∫–∞–Ω–∞–ª—ã\n",
       "\n",
       "[15] date=2025-06-30 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–ò–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞ —Ä—É—Ö–Ω—É–ª –Ω–∏–∂–µ 97 –ø—É–Ω–∫—Ç–æ–≤ –≤–ø–µ—Ä–≤—ã–µ —Å –º–∞—Ä—Ç–∞ 2022 –≥–æ–¥–∞. –û–Ω –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–∞–ª—é—Ç—ã –∫ –µ–≤—Ä–æ, –∏–µ–Ω–µ, —à–≤–µ–π—Ü–∞—Ä—Å–∫–æ–º—É —Ñ—Ä–∞–Ω–∫—É, –±—Ä–∏—Ç–∞–Ω—Å–∫–æ–º—É —Ñ—É–Ω—Ç—É, –∫–∞–Ω–∞–¥—Å–∫–æ–º—É –¥–æ–ª–ª–∞—Ä—É –∏ —à–≤–µ–¥—Å–∫–æ–π –∫—Ä–æ–Ω–µ. @bankrollo\n",
       "\n",
       "[16] date=2025-06-20 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–†–∞–≤–Ω–æ–≤–µ—Å–Ω—ã–º —Å–µ–π—á–∞—Å —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª—é—Ç–Ω—ã–π –∫—É—Ä—Å –≤—ã—à–µ 100 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä, –∑–∞—è–≤–∏–ª –≥–ª–∞–≤–∞ –°–±–µ—Ä–±–∞–Ω–∫–∞ –ì–µ—Ä–º–∞–Ω –ì—Ä–µ—Ñ. –û–Ω –¥–æ–±–∞–≤–∏–ª, —á—Ç–æ –Ω—ã–Ω–µ—à–Ω–∏–π ‚Äì –≥–æ—Ä–∞–∑–¥–æ –º–µ–Ω—å—à–∏–π ‚Äì –∫—É—Ä—Å –æ—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –≤—Å–µ —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã–µ –æ—Ç—Ä–∞—Å–ª–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–∏ –∏ –±—é–¥–∂–µ—Ç. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ –ø—è—Ç–Ω–∏—Ü—É —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 78,5 —Ä—É–±–ª—è.\n",
       "\n",
       "[17] date=2025-06-19 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –≤ —Ç–µ–∫—É—â–µ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –≤ —Ä–∞–π–æ–Ω–µ 100 —Ä—É–±–ª–µ–π –∑–∞ –¥–æ–ª–ª–∞—Ä, –∑–∞—è–≤–∏–ª –ø–µ—Ä–≤—ã–π –≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –ú–∞–Ω—Ç—É—Ä–æ–≤. –°–µ–≥–æ–¥–Ω—è –ø—Ä–∏ –∫—Ä–µ–ø–∫–æ–º —Ä—É–±–ª–µ —ç–∫—Å–ø–æ—Ä—Ç –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –æ—Ç—Ä–∞—Å–ª–µ–π –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –º–∞–ª–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º, –æ—Ç–º–µ—Ç–∏–ª –æ–Ω. @bankrollo\n",
       "\n",
       "[18] date=2025-06-12 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–ò–Ω–¥–µ–∫—Å –¥–æ–ª–ª–∞—Ä–∞ (–∫—É—Ä—Å –∫ –∫–æ—Ä–∑–∏–Ω–µ –≤–∞–ª—é—Ç —à–µ—Å—Ç–∏ —Å—Ç—Ä–∞–Ω - —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ –°–®–ê) –æ–ø—É—Å—Ç–∏–ª—Å—è –¥–æ –º–∏–Ω–∏–º—É–º–∞ —Å –≤–µ—Å–Ω—ã 2022-–≥–æ. –°–µ–π—á–∞—Å –æ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ 97,8 –ø—É–Ω–∫—Ç–∞.\n",
       "\n",
       "[19] date=2025-05-29 channel(s)=–†–∏–∞ –ù–æ–≤–æ—Å—Ç–∏\n",
       " document=–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ—Ç –¶–ë –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 79 —Ä—É–±–ª–µ–π. –ï–≥–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ —á–µ—Ç–≤–µ—Ä–≥ - 78,5 —Ä—É–±–ª—è.\n",
       "\n",
       "[20] date=2025-05-21 channel(s)=Forbes Russia\n",
       " document=–ë–∞–Ω–∫ –†–æ—Å—Å–∏–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª –Ω–∞ 22 –º–∞—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ 79,75 —Ä—É–±–ª—è. –ù–∏–∂–µ 80 —Ä—É–±–ª–µ–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –≤–ø–µ—Ä–≤—ã–µ —Å –º–∞—è 2023 –≥–æ–¥–∞. –ü—Ä–∏ —ç—Ç–æ–º –µ–≤—Ä–æ –ø–æ–¥–æ—Ä–æ–∂–∞–ª –¥–æ 91,29 —Ä—É–±–ª—è, –∞ —é–∞–Ω—å –ø–æ—á—Ç–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è\n",
       "\n",
       "[21] date=2025-04-21 channel(s)=–°–∏–≥–Ω–∞–ª—ã –†–¶–ë\n",
       " document=–¶–ë —É—Å—Ç–∞–Ω–æ–≤–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∏–∂–µ 81 —Ä—É–±–ª—è –≤–ø–µ—Ä–≤—ã–µ —Å –ª–µ—Ç–∞ 2023 –≥–æ–¥–∞ –¶–ë –†–§ —Å 22 –∞–ø—Ä–µ–ª—è —Å–Ω–∏–∑–∏–ª –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –°–®–ê –Ω–∞ 37.74 –∫–æ–ø., –¥–æ 80.7597 —Ä—É–±.\n",
       "\n",
       "[22] date=2025-04-21 channel(s)=–ë–ª—É–º–±–µ—Ä–≥\n",
       " document=–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –¥–æ 79 —Ä—É–±–ª–µ–π. üîµ Bloomberg\n",
       "\n",
       "[23] date=2025-04-14 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞; –ë–ª—É–º–±–µ—Ä–≥\n",
       " document=–¶–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫ –ø–æ–Ω–∏–∑–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 1 —Ä—É–±–ª—å, –µ–≤—Ä–æ ‚Äî –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 2. @bankrollo\n",
       "\n",
       "[24] date=2025-03-18 channel(s)=–†–∞–Ω—å—à–µ –≤—Å–µ—Ö. –ù—É –ø–æ—á—Ç–∏\n",
       " document=–í–Ω–µ–±–∏—Ä–∂–µ–≤–æ–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –æ–ø—É—Å—Ç–∏–ª—Å—è –Ω–∏–∂–µ 81 —Ä—É–±–ª—è\n",
       "\n",
       "[25] date=2025-03-17 channel(s)=–†–∞–Ω—å—à–µ –≤—Å–µ—Ö. –ù—É –ø–æ—á—Ç–∏\n",
       " document=–†–∞—Å—á–µ—Ç–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ - –æ—Ä–∏–µ–Ω—Ç–∏—Ä –¥–ª—è –≤–Ω–µ–±–∏—Ä–∂–µ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞ - —É–ø–∞–ª –Ω–∏–∂–µ 83 —Ä—É–±–ª–µ–π, –≤–ø–µ—Ä–≤—ã–µ —Å –ø—Ä–æ—à–ª–æ–≥–æ –ª–µ—Ç–∞, —Å–ª–µ–¥—É–µ—Ç –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤. –ö 17.02 –º—Å–∫ –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –ø–∞–¥–∞–µ—Ç –Ω–∞ 2,52 —Ä—É–±–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è - –¥–æ 82,87 —Ä—É–±–ª—è, –º–∏–Ω–∏–º—É–º–∞ —Å 27 –∞–≤–≥—É—Å—Ç–∞ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞.\n",
       "\n",
       "[26] date=2025-03-11 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–¶–ë –æ–ø—É—Å—Ç–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –¥–æ 86 —Ä—É–±–ª–µ–π. –ï–≤—Ä–æ —É–ø–∞–ª –¥–æ 93,6 —Ä—É–±–ª—è. @bankrollo\n",
       "\n",
       "[27] date=2024-12-24 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —É–ø–∞–ª –Ω–∏–∂–µ 100. @bankrollo\n",
       "\n",
       "[28] date=2024-12-06 channel(s)=–ë–∞–Ω–∫–∏, –¥–µ–Ω—å–≥–∏, –¥–≤–∞ –æ—Ñ—à–æ—Ä–∞\n",
       " document=–¶–ë –ø–æ–Ω–∏–∑–∏–ª –∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –Ω–∏–∂–µ 100, –µ–≤—Ä–æ ‚Äî –Ω–∏–∂–µ 107. @bankrollo\n",
       "\n",
       "[29] date=2024-11-27 channel(s)=–ë–ª—É–º–±–µ—Ä–≥\n",
       " document=–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ –ø–µ—Ä–µ–≤–∞–ª–∏–ª –∑–∞ 111 —Ä—É–±–ª–µ–π. UPD: –ö—É—Ä—Å —É–∂–µ 114. üîµ Bloomberg\n",
       "\n",
       "[30] date=2024-11-14 channel(s)=–≠–∫–æ–Ω–æ–º–∏–∫–∞ \n",
       " document=–ö—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞ —Ç–µ–ø–µ—Ä—å —Å—Ç–æ–∏—Ç –≤—ã—à–µ 100 —Ä—É–±–ª–µ–π. –≠—Ç–æ —Å–ª–µ–¥—É–µ—Ç –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ú–æ—Å–±–∏—Ä–∂–∏. ¬´–°—Ç–æ–∏–º–æ—Å—Ç—å –¥–æ–ª–ª–∞—Ä–∞ ‚Äî 100,2428 —Ä—É–±–ª—è¬ª, ‚Äî —Å–æ–æ–±—â–∞–µ—Ç —Ä–µ–≥—É–ª—è—Ç–æ—Ä. –¢–∞–∫–æ–≥–æ —Å–∫–∞—á–∫–∞ –Ω–µ –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤. –°–µ–π—á–∞—Å –¶–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫ —Å–∞–º —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç —Ü–µ–Ω—É –¥–æ–ª–ª–∞—Ä–∞ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ —Ä—É–±–ª—é. –≠—Ç–æ —Å—Ç–∞–ª–æ —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º —Å–∞–Ω–∫—Ü–∏–π –°–®–ê. ùîº‚ÑÇùïÜ‚ÑïùïÜùïÑùïÄùïÇùî∏"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_summary(out[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c19deabb-38f1-46f7-817d-ad259a0a74b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 124, 121)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[\"candidates\"]), len(out[\"candidates_dedup\"]), len(out[\"candidates_filtered\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d1d99-c8a5-4c41-8e12-70ccef824d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ebafb-e7ca-423b-949b-86bad48b8378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58069a8-6326-4db4-a4ad-d93f352638de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db71e0-e65e-4243-bbc9-40a57ee5b077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa86a20-14cf-48d4-89e4-80f66537337e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1578-a774-4a1f-ba07-c3e2db786e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6a85c-9116-434c-84d9-1bf8fc18ebdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34296b50-956e-4686-bf34-1e18d2893733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "local/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
